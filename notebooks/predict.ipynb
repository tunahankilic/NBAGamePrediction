{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tunahankilic/Desktop/NBAGamePrediction'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/nba_games.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['season'] > '2018'].sort_values(\"date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"index_opp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mp', 'fg', 'fga', 'fg%', '3p', '3pa', '3p%', 'ft', 'fta', 'ft%', 'orb',\n",
       "       'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'ts%', 'efg%',\n",
       "       '3par', 'ftr', 'orb%', 'drb%', 'trb%', 'ast%', 'stl%', 'blk%', 'tov%',\n",
       "       'usg%', 'ortg', 'drtg', 'pace', 'ft/fga', 'team', 'total', 'home',\n",
       "       'mp_opp', 'fg_opp', 'fga_opp', 'fg%_opp', '3p_opp', '3pa_opp',\n",
       "       '3p%_opp', 'ft_opp', 'fta_opp', 'ft%_opp', 'orb_opp', 'drb_opp',\n",
       "       'trb_opp', 'ast_opp', 'stl_opp', 'blk_opp', 'tov_opp', 'pf_opp',\n",
       "       'pts_opp', 'ts%_opp', 'efg%_opp', '3par_opp', 'ftr_opp', 'orb%_opp',\n",
       "       'drb%_opp', 'trb%_opp', 'ast%_opp', 'stl%_opp', 'blk%_opp', 'tov%_opp',\n",
       "       'usg%_opp', 'ortg_opp', 'drtg_opp', 'pace_opp', 'ft/fga_opp',\n",
       "       'team_opp', 'total_opp', 'home_opp', 'season', 'date', 'won'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(team: pd.DataFrame):\n",
    "    team[\"target\"] = team[\"won\"].shift(-1)\n",
    "    team[\"target\"] = team[\"target\"].map({True: 1, False: 0}).fillna(-1).astype(int)\n",
    "    return team\n",
    "\n",
    "\n",
    "df = df.groupby(\"team\", group_keys=False).apply(create_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days_difference(team: pd.DataFrame):\n",
    "    team['days_to_next_game'] = team['date'].diff().dt.days.shift(-1)\n",
    "    return team\n",
    "\n",
    "\n",
    "df = df.groupby(['team', 'season'], group_keys=False).apply(calculate_days_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mp', 'fg', 'fga', 'fg%', '3p', '3pa', '3p%', 'ft', 'fta', 'ft%', 'orb',\n",
       "       'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'ts%', 'efg%',\n",
       "       '3par', 'ftr', 'orb%', 'drb%', 'trb%', 'ast%', 'stl%', 'blk%', 'tov%',\n",
       "       'usg%', 'ortg', 'drtg', 'pace', 'ft/fga', 'total', 'home', 'mp_opp',\n",
       "       'fg_opp', 'fga_opp', 'fg%_opp', '3p_opp', '3pa_opp', '3p%_opp',\n",
       "       'ft_opp', 'fta_opp', 'ft%_opp', 'orb_opp', 'drb_opp', 'trb_opp',\n",
       "       'ast_opp', 'stl_opp', 'blk_opp', 'tov_opp', 'pf_opp', 'pts_opp',\n",
       "       'ts%_opp', 'efg%_opp', '3par_opp', 'ftr_opp', 'orb%_opp', 'drb%_opp',\n",
       "       'trb%_opp', 'ast%_opp', 'stl%_opp', 'blk%_opp', 'tov%_opp', 'usg%_opp',\n",
       "       'ortg_opp', 'drtg_opp', 'pace_opp', 'ft/fga_opp', 'total_opp',\n",
       "       'home_opp', 'days_to_next_game'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_averages(team: pd.DataFrame, window: int):\n",
    "    rolling = team.rolling(window=window).mean()\n",
    "    return rolling\n",
    "\n",
    "\n",
    "df_rolling = df.groupby([\"team\", \"season\"], group_keys=False)[selected_columns].apply(rolling_averages, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_cols = [f'{col}_10' for col in df_rolling.columns]\n",
    "df_rolling.columns = rolling_cols\n",
    "\n",
    "df = pd.concat([df, df_rolling], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.drop(df[df['target'] == -1].index).reset_index(drop=True).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    df = df.copy()\n",
    "    return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "\n",
    "df_filtered[\"home_next\"] = add_col(df_filtered, \"home\")\n",
    "df_filtered[\"team_opp_next\"] = add_col(df_filtered, \"team_opp\")\n",
    "df_filtered[\"date_next\"] = add_col(df_filtered, \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>team_opp</th>\n",
       "      <th>date</th>\n",
       "      <th>team_opp_next</th>\n",
       "      <th>date_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHI</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHO</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAL</td>\n",
       "      <td>CHO</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAL</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHI</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10169</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10170</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10171</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10174 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team team_opp       date team_opp_next  date_next\n",
       "0      PHI      LAC 2019-01-01           PHO 2019-01-02\n",
       "1      CHO      DAL 2019-01-02           DEN 2019-01-05\n",
       "2      DAL      CHO 2019-01-02           BOS 2019-01-04\n",
       "3      LAL      OKC 2019-01-02           NYK 2019-01-04\n",
       "4      PHI      PHO 2019-01-02           DAL 2019-01-05\n",
       "...    ...      ...        ...           ...        ...\n",
       "10169  DEN      MIA 2023-06-04           MIA 2023-06-07\n",
       "10170  MIA      DEN 2023-06-07           DEN 2023-06-09\n",
       "10171  DEN      MIA 2023-06-07           MIA 2023-06-09\n",
       "10172  DEN      MIA 2023-06-09          None        NaT\n",
       "10173  MIA      DEN 2023-06-09          None        NaT\n",
       "\n",
       "[10174 rows x 5 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[['team', 'team_opp', 'date', 'team_opp_next', 'date_next']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_filtered.merge(\n",
    "    df_filtered[rolling_cols + [\"team_opp_next\", \"date_next\", \"team\"]],\n",
    "    left_on = [\"team\", \"date_next\"],\n",
    "    right_on = [\"team_opp_next\", \"date_next\"],\n",
    "    suffixes=('', '_nopp')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>team_opp</th>\n",
       "      <th>date</th>\n",
       "      <th>team_opp_next</th>\n",
       "      <th>date_next</th>\n",
       "      <th>days_to_next_game_10</th>\n",
       "      <th>team_nopp</th>\n",
       "      <th>team_opp_next_nopp</th>\n",
       "      <th>days_to_next_game_10_nopp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHI</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>7.9</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>GSW</td>\n",
       "      <td>SAC</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSW</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>SAC</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>8.1</td>\n",
       "      <td>SAC</td>\n",
       "      <td>GSW</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NYK</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>POR</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>8.2</td>\n",
       "      <td>POR</td>\n",
       "      <td>NYK</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAL</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>MIN</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>7.8</td>\n",
       "      <td>MIN</td>\n",
       "      <td>LAL</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>2.6</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>3.3</td>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>2.3</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>3.3</td>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9954 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team team_opp       date team_opp_next  date_next  days_to_next_game_10  \\\n",
       "0     PHI      PHO 2019-01-02           DAL 2019-01-05                   7.9   \n",
       "1     SAC      DEN 2019-01-03           GSW 2019-01-05                   8.0   \n",
       "2     GSW      HOU 2019-01-03           SAC 2019-01-05                   8.1   \n",
       "3     NYK      LAL 2019-01-04           POR 2019-01-07                   8.2   \n",
       "4     LAL      NYK 2019-01-04           MIN 2019-01-06                   7.8   \n",
       "...   ...      ...        ...           ...        ...                   ...   \n",
       "9949  MIA      DEN 2023-06-01           DEN 2023-06-04                   2.5   \n",
       "9950  MIA      DEN 2023-06-04           DEN 2023-06-07                   2.6   \n",
       "9951  DEN      MIA 2023-06-04           MIA 2023-06-07                   3.3   \n",
       "9952  MIA      DEN 2023-06-07           DEN 2023-06-09                   2.3   \n",
       "9953  DEN      MIA 2023-06-07           MIA 2023-06-09                   3.3   \n",
       "\n",
       "     team_nopp team_opp_next_nopp  days_to_next_game_10_nopp  \n",
       "0          DAL                PHI                        7.7  \n",
       "1          GSW                SAC                        8.1  \n",
       "2          SAC                GSW                        8.0  \n",
       "3          POR                NYK                        7.9  \n",
       "4          MIN                LAL                        8.1  \n",
       "...        ...                ...                        ...  \n",
       "9949       DEN                MIA                        3.4  \n",
       "9950       DEN                MIA                        3.3  \n",
       "9951       MIA                DEN                        2.6  \n",
       "9952       DEN                MIA                        3.3  \n",
       "9953       MIA                DEN                        2.3  \n",
       "\n",
       "[9954 rows x 9 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[['team', 'team_opp', 'date', 'team_opp_next', 'date_next', 'days_to_next_game_10', 'team_nopp', 'team_opp_next_nopp', 'days_to_next_game_10_nopp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['team', 'team_opp', 'season', 'team_opp_next', 'team_opp_next_nopp',\n",
       "       'team_nopp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns[df_full.dtypes == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_full.loc[df_full[\"season\"] < \"2023\"]\n",
    "test = df_full.loc[df_full[\"season\"] == \"2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.loc[df_full[\"season\"] < \"2023\"].to_parquet('data/train.parquet')\n",
    "df_full.loc[df_full[\"season\"] == \"2023\"].to_parquet('data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_classifier = RidgeClassifier(alpha=1)\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "sfs = SequentialFeatureSelector(rc_classifier, n_features_to_select=30, direction=\"forward\", cv=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_cols = ['team', 'team_opp', 'season', 'date', 'won', 'team_opp_next',\n",
    "       'date_next', 'team_opp_nopp', 'team_nopp', \"team_opp_next_nopp\", \"target\"]\n",
    "\n",
    "selected_cols = df_full.columns[~df_full.columns.isin(removed_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train.loc[:, selected_cols] = scaler.fit_transform(train[selected_cols])\n",
    "test.loc[:, selected_cols] = scaler.transform(test[selected_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(train, test, model, predictors, season=2023):\n",
    "    all_predictions = []\n",
    "    model.fit(train[predictors], train['target'])\n",
    "    #train_preds = model.predict(train[predictors])\n",
    "    print(f'Season - {season}')\n",
    "    #print(f'Train Accuracy - {accuracy_score(train[\"target\"], train_preds)}')\n",
    "    preds = model.predict(test[predictors])\n",
    "    print(f'Test Accuracy - {accuracy_score(test[\"target\"], preds)}')\n",
    "    print(f'Precision: {precision_score(test[\"target\"], preds)}')\n",
    "    print(f'Recall: {recall_score(test[\"target\"], preds)}')\n",
    "    preds = pd.Series(preds, index=test.index)\n",
    "    combined = pd.concat([test[\"target\"], preds], axis=1)\n",
    "    combined.columns = ['actual', 'prediction']\n",
    "    all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-36 {color: black;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=30)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=30)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.fit(train[selected_cols], train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(selected_cols[sfs.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drb',\n",
       " 'pf',\n",
       " 'usg%',\n",
       " 'fg_opp',\n",
       " '3p_opp',\n",
       " 'tov_opp',\n",
       " 'usg%_opp',\n",
       " 'days_to_next_game',\n",
       " 'tov%_10',\n",
       " 'usg%_10',\n",
       " 'ortg_10',\n",
       " 'drtg_10',\n",
       " 'pace_10',\n",
       " 'fg_opp_10',\n",
       " '3p%_opp_10',\n",
       " 'ft%_opp_10',\n",
       " 'pts_opp_10',\n",
       " 'usg%_opp_10',\n",
       " 'ortg_opp_10',\n",
       " 'drtg_opp_10',\n",
       " 'pace_opp_10',\n",
       " 'total_opp_10',\n",
       " 'home_next',\n",
       " 'fg_10_nopp',\n",
       " '3p%_10_nopp',\n",
       " 'trb_10_nopp',\n",
       " 'usg%_10_nopp',\n",
       " 'ortg_10_nopp',\n",
       " 'usg%_opp_10_nopp',\n",
       " 'drtg_opp_10_nopp']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def run_optimization(data: pd.DataFrame, columns: list, num_trials: int):\n",
    "\n",
    "    train = data[data[\"season\"] < '2022']\n",
    "    val = data[data[\"season\"] == \"2022\"]\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': 1000,\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 20, 1),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10, 1),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4, 1),\n",
    "            'random_state': 2023,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "\n",
    "        rf = RandomForestClassifier(**params)\n",
    "        rf.fit(train[cols], train[\"target\"])\n",
    "        y_pred = rf.predict(val[cols])\n",
    "        accuracy = accuracy_score(val[\"target\"], y_pred)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    sampler = TPESampler(seed=2023)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(data: pd.DataFrame, columns: list, num_trials: int):\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        X = train[columns]\n",
    "        y = train[\"target\"]\n",
    "        # Define hyperparameter search space\n",
    "        n_estimators = 1000\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10, 1)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5, 1)\n",
    "        \n",
    "        # Create the model with suggested hyperparameters\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=2023\n",
    "        )\n",
    "        \n",
    "        # Define TimeSeriesSplit cross-validation\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # Calculate the performance metric using cross_val_score and TimeSeriesSplit\n",
    "        scores = cross_val_score(model, X, y, cv=tscv, scoring='accuracy')\n",
    "        \n",
    "        # Return the average accuracy (Optuna maximizes the objective)\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')  # We want to maximize the accuracy\n",
    "    study.optimize(objective, n_trials=num_trials)  # You can increase the number of trials for a more thorough search\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))\n",
    "    return trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-30 14:38:04,944] A new study created in memory with name: no-name-68bf36d7-b653-44b6-a6be-bb935b4738b4\n",
      "[I 2023-07-30 14:38:19,726] Trial 0 finished with value: 0.6034428794992175 and parameters: {'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.6034428794992175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  1\n",
      "Best trial:\n",
      "  Value:  0.6034428794992175\n",
      "  Params: \n",
      "    max_depth: 5\n",
      "    min_samples_split: 10\n",
      "    min_samples_leaf: 3\n"
     ]
    }
   ],
   "source": [
    "best = run_optimization(train, cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=5, min_samples_split=6, min_samples_leaf=1, n_estimators=1000, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season - 2023\n",
      "Test Accuracy - 0.5853765323992994\n",
      "Precision: 0.6145710928319624\n",
      "Recall: 0.45796847635726795\n"
     ]
    }
   ],
   "source": [
    "predictions = backtest(train, test, rf, cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('NBAGamePrediction-N2JfDsTU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f7a4617d41574ffd6beedec7195318bd6d803125dd255aceeca4a162991d8c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
